#**Coding exercise: analyzing user sessions**

This application helps find most active users provided server access log.

To Run the application :
1. Download server access logs and unzip it
2. Compile code and generate Jar using
   > `mvn clean package`
3. Copy the location of access logs and provide as argument
   >`java -jar target/imply-analyse-1.0-SNAPSHOT.jar "src/main/resources/access.log"`
4. Provide the input (as numeric) to filter users based on distinct access pages in the console
5. Output is written into file `imply-analyse/workingDir/output/results.txt`

## Approach
1. Given a unzipped input file, a `FileReaderService` reads this file using random access concurrently using executor service.
2. A simple hash based partitoiner (`SimpleHashPartitioner`) is used to partition the read lines and add them into predefined set of `ArrayBlockingQueue`. This acts as producer. This approach is taken to batch the writes to disk which reduces number of IO operations.
3. `SplitFileWriterService` takes care of spawning consumer tasks to consume lines from each `ArrayBlockingQueue` and write them into `IConstants.MAP0_LOCATION` directory
4. After the completion of above step, `CountMapperService` kicks into transform each partition file from previous step to map of userID to unique server page lists. This result is written into `IConstants.MAP1_LOCATION`. This serves as read optimised data to server filter queries  quickly.
5. The program promts to accept input from user for numeric input to filter the distinct number of visited pages by users.
6. `FilterMapperService` service kicks in by iterating through all files generated by step 4 and writes the desired results into `IConstants.OUTPUT_FILE_LOCATION`.
7. Step 5 & 6 repeats itself untill the program is killed.


## Future Scope for improvement
1. Make the code to obtain configurations from a file
2. Extend code to read and write data from variety of file storage engines like HDFS, S3, etc.
3. Handle data skews efficiently by intelligently partitioning